/**
 * Dynamic Memory Retention System for Spectre AI
 *
 * This module implements a rolling buffer with intelligent summarization
 * to maintain long-term context while staying within token budget constraints.
 *
 * Architecture:
 * - Recent messages stored as raw text (full fidelity)
 * - Older messages compressed into summaries via Gemini
 * - Memory bank periodically re-summarized to prevent unbounded growth
 *
 * Benefits:
 * - Predictable token usage (capped at ~50k input tokens)
 * - Scales to arbitrarily long conversations
 * - Preserves critical context (decisions, code changes, intents)
 * - No hard-coded limits on message length
 */

/**
 * Raw message with full content preserved in rolling buffer.
 */
export interface RawMessage {
  /** Unique identifier for tracking and summarization */
  id: string;

  /** Message role: user input or AI response */
  role: 'user' | 'assistant';

  /** Full message text */
  text: string;

  /** Timestamp for aging and cleanup */
  timestamp: number;

  /** Estimated token count (cached for performance) */
  estimatedTokens?: number;
}

/**
 * Summarized representation of one or more old messages.
 * Generated by Gemini with focus on key decisions, intents, and code changes.
 */
export interface SummaryEntry {
  /** Unique identifier */
  id: string;

  /** Condensed summary text focusing on actionable context */
  summary: string;

  /** IDs of original messages that were summarized */
  originalMessageIds: string[];

  /** Timestamp when summary was created */
  createdAt: number;

  /** Estimated token count (cached) */
  estimatedTokens?: number;

  /** Optional: categorization for better retrieval */
  category?:
    | 'code_change'
    | 'configuration'
    | 'debugging'
    | 'learning'
    | 'general';
}

/**
 * Memory bank: collection of summaries representing historical context.
 * Periodically re-summarized when approaching token cap.
 */
export interface MemoryBank {
  /** All summary entries, oldest first */
  summaries: SummaryEntry[];

  /** Total estimated tokens across all summaries */
  totalTokens: number;

  /** Last time memory bank was re-summarized/compressed */
  lastCompressedAt?: number;

  /** Version for migration compatibility */
  version: number;
}

/**
 * Complete conversation state with dynamic memory management.
 */
export interface ConversationMemory {
  /** Session identifier */
  sessionId: string;

  /** Recent messages in rolling buffer (full fidelity) */
  recentMessages: RawMessage[];

  /** Compressed historical context */
  memoryBank: MemoryBank;

  /** Configuration for this conversation */
  config: MemoryConfig;

  /** Statistics for monitoring */
  stats: {
    totalInteractions: number;
    summarizationsPerformed: number;
    lastSummarizedAt?: number;
  };
}

/**
 * Configuration for memory retention behavior.
 */
export interface MemoryConfig {
  /** Max raw messages to keep before summarization (default: 15 turns = 30 messages) */
  maxRecentMessages: number;

  /** Soft cap for memory bank tokens (default: 50k) */
  memoryBankTokenCap: number;

  /** When to trigger summarization of recent messages */
  summarizationTrigger: {
    /** Min messages before considering summarization */
    minMessages: number;

    /** Or when recent messages exceed this token count */
    maxTokens: number;
  };

  /** When to re-compress the memory bank */
  compressionTrigger: {
    /** Percentage of cap before compressing (e.g., 0.8 = 80%) */
    threshold: number;
  };
}

/**
 * Default configuration values.
 *
 * OPTIMIZED FOR GEMINI 2.5 (1M context window, 250k TPM free tier)
 * - Increased from 50k to 100k memory bank (still only 10% of context window)
 * - More tolerance before summarization (better retention)
 * - Later compression trigger (preserves detail longer)
 */
export const DEFAULT_MEMORY_CONFIG: MemoryConfig = {
  maxRecentMessages: 40, // 20 turns (user + assistant pairs) - increased from 30
  memoryBankTokenCap: 100_000, // Doubled: Still well below 1M limit, allows richer history
  summarizationTrigger: {
    minMessages: 30, // Summarize when buffer has 30+ messages (was 20)
    maxTokens: 25_000, // Or when recent messages > 25k tokens (was 15k)
  },
  compressionTrigger: {
    threshold: 0.9, // Compress when memory bank reaches 90% of cap = 90k tokens (was 80%)
  },
};

/**
 * Token counting result with breakdown.
 */
export interface TokenCount {
  /** Total tokens */
  total: number;

  /** Breakdown by source */
  breakdown: {
    recentMessages: number;
    memoryBank: number;
    currentPrompt: number;
    systemPrompt: number;
  };
}

/**
 * Options for prompt assembly.
 */
export interface PromptAssemblyOptions {
  /** Current user input */
  currentPrompt: string;

  /** Sketch files or other context to include */
  additionalContext?: string;

  /** Force inclusion of specific message IDs */
  pinMessages?: string[];

  /** Target token budget (will trim if needed) */
  targetTokenBudget?: number;
}
